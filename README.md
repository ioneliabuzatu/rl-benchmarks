# rl-benchmarks

https://hackmd.io/@92tLxRFMRF-iTbw8_IQU6Q/Sk6aw_wjP/edit

## TODO models implemnetation

1. - [X] [Lillicrap et al., 2015, (DDPG) Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971)
2. - [ ] [Silver et al., (DPG)](https://deepmind.com/research/publications/deterministic-policy-gradient-algorithms)
3. - [ ] [Mnih et al., 2013 (DQN)](https://arxiv.org/abs/1312.5602)
4. - [ ] [Twin Delayed DDPG (TD3)](https://spinningup.openai.com/en/latest/algorithms/td3.html)
5. - [ ] [Fujimote et al., 2018 (error Actor-Critic)](https://arxiv.org/abs/1802.09477)
6. - [ ] [ Hasselt et al., 2018 - (Insatiability of target network) Deep Reinforcement Learning and the Deadly Triad](https://arxiv.org/pdf/1812.02648.pdf)
8. - [ ] [Schulman et al., Trust Region Policy Optimization](https://arxiv.org/pdf/1502.05477.pdf)
9. - [ ] [Mnih et al., Asynchronous Methods for Deep Reinforcement Learning](https://arxiv.org/pdf/1602.01783.pdf)
10. - [ ] [Shixiang et al., Continuous Deep Q-Learning with Model-based Acceleration](https://arxiv.org/pdf/1603.00748.pdf)
11. - [ ] [Schulman et al., Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347.pdf)
12. - [ ] [Haarnoja et al., Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/pdf/1801.01290.pdf)
13. - [ ] [Thomas,2014, Bias in Natural Actor-Critic Algorithms](http://proceedings.mlr.press/v32/thomas14.pdf)
14. - [ ] [link text](https:// "title")
15. - [ ] [link text](https:// "title")
16. - [ ] [link text](https:// "title")
17. - [ ] [link text](https:// "title")

## TODO rsults environment 

1. - [] [link environment]()
2. - [] [link environment]()
1. - [] [link environment]()
